{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "import math\n",
    "\n",
    "__all__ = ['mobilenext']\n",
    "\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "def conv_3x3_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "class SandGlass(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, reduction_ratio):\n",
    "        super(SandGlass, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = round(inp // reduction_ratio)\n",
    "        self.identity = stride == 1 and inp == oup\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            # dw\n",
    "            nn.Conv2d(inp, inp, 3, 1, 1, groups=inp, bias=False),\n",
    "            nn.BatchNorm2d(inp),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            # pw-linear\n",
    "            nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            # pw\n",
    "            nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(oup),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            # dw-linear\n",
    "            nn.Conv2d(oup, oup, 3, stride, 1, groups=oup, bias=False),\n",
    "            nn.BatchNorm2d(oup),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNeXt(nn.Module):\n",
    "    def __init__(self, num_classes=1000, width_mult=1.):\n",
    "        super(MobileNeXt, self).__init__()\n",
    "        # setting of sandglass blocks\n",
    "        self.cfgs = [\n",
    "            # t, c, n, s\n",
    "            [2, 96, 1, 2],\n",
    "            [6, 144, 1, 1],\n",
    "            [6, 192, 3, 2],\n",
    "            [6, 288, 3, 2],\n",
    "            [6, 384, 4, 1],\n",
    "            [6, 576, 4, 2],\n",
    "            [6, 960, 3, 1],\n",
    "            [6, 1280, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(32 * width_mult, 8)\n",
    "        layers = [conv_3x3_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        block = SandGlass\n",
    "        for t, c, n, s in self.cfgs:\n",
    "            output_channel = _make_divisible(c * width_mult, 8)\n",
    "            for i in range(n):\n",
    "                layers.append(block(input_channel, output_channel, s if i == 0 else 1, t))\n",
    "                input_channel = output_channel\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        # building last several layers\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(output_channel, num_classes)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def mobilenext(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a MobileNeXt model\n",
    "    \"\"\"\n",
    "    return MobileNeXt(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_cifar100(batch_size=128):\n",
    "    transform_train = torchvision.transforms.Compose([\n",
    "        # torchvision.transforms.Resize(256),\n",
    "        # torchvision.transforms.CenterCrop(224),\n",
    "        torchvision.transforms.Resize(40),\n",
    "        torchvision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0),\n",
    "                                                 ratio=(1.0, 1.0)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
    "                                         [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "    transform_test = torchvision.transforms.Compose([\n",
    "        # torchvision.transforms.Resize(256),\n",
    "        # torchvision.transforms.CenterCrop(224),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
    "                                         [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                             download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=0)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                            download=True, transform=transform_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                             shuffle=False, num_workers=0)\n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "def train_batch(net, X, y, loss, trainer, devices):\n",
    "    X = X.to(devices)\n",
    "    y = y.to(devices)\n",
    "    net.train()\n",
    "    trainer.zero_grad()\n",
    "    pred = net(X)\n",
    "    l = loss(pred, y)\n",
    "    l.sum().backward()\n",
    "    trainer.step()\n",
    "    train_loss_sum = l.sum()\n",
    "    train_acc_sum = d2l.accuracy(pred, y)\n",
    "    return train_loss_sum, train_acc_sum\n",
    "\n",
    "\n",
    "def train(net, train_iter, valid_iter, num_epochs, loss, trainer, lr_period,\n",
    "          lr_decay, use_sl=True, device=d2l.try_gpu()):\n",
    "    if use_sl:\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_period, lr_decay)\n",
    "    num_batches, timer = len(train_iter), d2l.Timer()\n",
    "    legend = ['train loss', 'train acc']\n",
    "    if valid_iter is not None:\n",
    "        legend.append('valid acc')\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "                            legend=legend)\n",
    "    net = net.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        metric = d2l.Accumulator(3)\n",
    "        for i, (features, labels) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            l, acc = train_batch(net, features, labels, loss,\n",
    "                                 trainer, device)\n",
    "            metric.add(l, acc, labels.shape[0])\n",
    "            timer.stop()\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(\n",
    "                    epoch + (i + 1) / num_batches,\n",
    "                    (metric[0] / metric[2], metric[1] / metric[2], None))\n",
    "        if valid_iter is not None:\n",
    "            valid_acc = evaluate_accuracy(net, valid_iter)\n",
    "            animator.add(epoch + 1, (None, None, valid_acc))\n",
    "        if use_sl:\n",
    "            scheduler.step()\n",
    "    measures = (f'train loss {metric[0] / metric[2]:.3f}, '\n",
    "                f'train acc {metric[1] / metric[2]:.3f}')\n",
    "    if valid_iter is not None:\n",
    "        measures += f', valid acc {valid_acc:.3f}'\n",
    "    print(measures + f'\\n{metric[2] * num_epochs / timer.sum():.1f}'\n",
    "                     f' examples/sec')\n",
    "\n",
    "\n",
    "def evaluate_accuracy(net, data_iter, device=None):\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    metric = d2l.Accumulator(2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(d2l.accuracy(net(X), y), d2l.size(y))\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "\n",
    "def train_fine_tuning(net, learning_rate, lr_period, lr_decay, train_iter, valid_iter, loss, num_epochs=5,\n",
    "                      param_group=True):\n",
    "    if param_group:\n",
    "        params_1x = [param for name, param in net.named_parameters()\n",
    "                     if name not in [\"fc.weight\", \"fc.bias\"]]\n",
    "        trainer = torch.optim.SGD([{'params': params_1x},\n",
    "                                   {'params': net.fc.parameters(),\n",
    "                                    'lr': learning_rate * 10}],\n",
    "                                  lr=learning_rate, weight_decay=0.001)\n",
    "    else:\n",
    "        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "    train(net, train_iter, valid_iter, num_epochs, loss, trainer, lr_period, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.774, train acc 0.767, valid acc 0.368\n",
      "393.9 examples/sec\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"232.60625pt\" height=\"180.65625pt\" viewBox=\"0 0 232.60625 180.65625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-06-05T03:16:38.260674</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 180.65625 \nL 232.60625 180.65625 \nL 232.60625 0 \nL 0 0 \nL 0 180.65625 \nz\n\" style=\"fill: none\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 20.5625 143.1 \nL 215.8625 143.1 \nL 215.8625 7.2 \nL 20.5625 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 58.044318 143.1 \nL 58.044318 7.2 \n\" clip-path=\"url(#p397b4bb489)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path id=\"m2c5345dc21\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m2c5345dc21\" x=\"58.044318\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 20 -->\n      <g transform=\"translate(51.681818 157.698438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 97.498864 143.1 \nL 97.498864 7.2 \n\" clip-path=\"url(#p397b4bb489)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m2c5345dc21\" x=\"97.498864\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 40 -->\n      <g transform=\"translate(91.136364 157.698438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 136.953409 143.1 \nL 136.953409 7.2 \n\" clip-path=\"url(#p397b4bb489)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m2c5345dc21\" x=\"136.953409\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 60 -->\n      <g transform=\"translate(130.590909 157.698438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 176.407955 143.1 \nL 176.407955 7.2 \n\" clip-path=\"url(#p397b4bb489)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m2c5345dc21\" x=\"176.407955\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 80 -->\n      <g transform=\"translate(170.045455 157.698438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 215.8625 143.1 \nL 215.8625 7.2 \n\" clip-path=\"url(#p397b4bb489)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m2c5345dc21\" x=\"215.8625\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <g transform=\"translate(206.31875 157.698438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- epoch -->\n     <g transform=\"translate(102.984375 171.376563)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_11\">\n      <path d=\"M 20.5625 137.387149 \nL 215.8625 137.387149 \n\" clip-path=\"url(#p397b4bb489)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <defs>\n       <path id=\"m599724e952\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m599724e952\" x=\"20.5625\" y=\"137.387149\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(7.2 141.186368)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_13\">\n      <path d=\"M 20.5625 111.04176 \nL 215.8625 111.04176 \n\" clip-path=\"url(#p397b4bb489)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m599724e952\" x=\"20.5625\" y=\"111.04176\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 1 -->\n      <g transform=\"translate(7.2 114.840979)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_15\">\n      <path d=\"M 20.5625 84.696371 \nL 215.8625 84.696371 \n\" clip-path=\"url(#p397b4bb489)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#m599724e952\" x=\"20.5625\" y=\"84.696371\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2 -->\n      <g transform=\"translate(7.2 88.495589)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_17\">\n      <path d=\"M 20.5625 58.350981 \nL 215.8625 58.350981 \n\" clip-path=\"url(#p397b4bb489)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#m599724e952\" x=\"20.5625\" y=\"58.350981\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 3 -->\n      <g transform=\"translate(7.2 62.1502)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_19\">\n      <path d=\"M 20.5625 32.005592 \nL 215.8625 32.005592 \n\" clip-path=\"url(#p397b4bb489)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use xlink:href=\"#m599724e952\" x=\"20.5625\" y=\"32.005592\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 4 -->\n      <g transform=\"translate(7.2 35.804811)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 18.983309 13.467987 \nL 19.376846 13.377273 \nL 20.163918 14.11094 \nL 20.557455 14.714412 \nL 20.5625 14.708278 \nL 20.956036 17.94185 \nL 21.349573 19.705624 \nL 21.743109 20.206907 \nL 22.535227 21.767137 \nL 22.928764 27.090464 \nL 24.109373 28.735292 \nL 24.507955 29.356026 \nL 24.901491 35.498552 \nL 26.480682 36.077337 \nL 26.874218 40.79922 \nL 27.267755 39.80194 \nL 27.661291 39.63753 \nL 28.453409 40.32129 \nL 28.846945 44.094057 \nL 30.027555 44.393028 \nL 30.426136 44.542113 \nL 30.819673 47.005738 \nL 31.213209 47.594246 \nL 31.606746 47.880146 \nL 32.398864 47.968549 \nL 32.7924 51.54547 \nL 33.185936 51.055611 \nL 33.579473 50.890919 \nL 34.371591 51.149466 \nL 34.765127 53.058978 \nL 35.158664 52.576715 \nL 35.5522 52.85037 \nL 36.344318 53.121706 \nL 36.737855 55.626078 \nL 37.131391 55.181685 \nL 37.524927 55.050703 \nL 38.317045 55.282963 \nL 38.710582 58.29683 \nL 39.104118 57.428162 \nL 39.497655 57.464313 \nL 40.289773 57.147609 \nL 40.683309 58.63275 \nL 41.076846 58.830516 \nL 41.470382 58.531023 \nL 42.2625 58.744081 \nL 42.656036 60.735585 \nL 43.049573 60.920016 \nL 43.443109 60.426003 \nL 44.230182 60.361227 \nL 44.235227 60.36499 \nL 44.628764 62.513098 \nL 45.809373 62.194081 \nL 46.207955 62.190933 \nL 46.601491 64.899487 \nL 46.995027 64.295444 \nL 47.7821 63.693671 \nL 48.180682 63.688738 \nL 48.574218 65.009927 \nL 48.967755 65.331657 \nL 49.361291 65.152551 \nL 49.754827 65.173465 \nL 50.153409 65.042568 \nL 50.546945 66.984947 \nL 51.727555 66.42981 \nL 52.126136 66.173268 \nL 52.519673 68.285085 \nL 52.913209 67.396566 \nL 53.306746 67.408667 \nL 54.098864 67.217593 \nL 54.4924 70.317455 \nL 54.885936 69.381958 \nL 55.279473 68.951711 \nL 56.071591 68.562322 \nL 56.465127 71.174544 \nL 56.858664 70.050575 \nL 58.044318 69.556006 \nL 58.437855 71.856221 \nL 58.831391 71.29698 \nL 59.618464 70.827912 \nL 60.017045 70.692392 \nL 60.410582 72.535866 \nL 60.804118 71.994464 \nL 61.197655 71.977885 \nL 61.989773 71.63275 \nL 62.383309 73.499621 \nL 63.563918 72.680722 \nL 63.9625 72.584149 \nL 64.356036 74.450451 \nL 65.143109 74.112169 \nL 65.536646 73.844552 \nL 65.935227 73.804618 \nL 66.328764 75.442656 \nL 67.115836 74.881137 \nL 67.509373 74.589614 \nL 67.907955 74.441573 \nL 68.301491 75.683232 \nL 69.4821 75.581185 \nL 69.880682 75.43586 \nL 70.274218 78.051187 \nL 70.667755 77.767531 \nL 71.061291 76.982988 \nL 71.454827 76.51554 \nL 71.853409 76.408324 \nL 72.246945 78.434494 \nL 72.640482 77.762574 \nL 73.034018 77.607865 \nL 73.427555 77.577463 \nL 73.826136 77.358724 \nL 74.219673 78.96192 \nL 74.613209 78.546843 \nL 75.798864 78.20433 \nL 76.1924 80.820635 \nL 76.585936 80.340316 \nL 76.979473 79.529325 \nL 77.771591 78.891592 \nL 78.165127 81.454916 \nL 78.558664 80.822646 \nL 79.345736 80.191579 \nL 79.739273 79.944387 \nL 79.744318 79.95532 \nL 80.137855 83.136616 \nL 80.531391 81.814052 \nL 80.924927 81.098981 \nL 81.318464 80.786171 \nL 81.717045 80.645902 \nL 82.110582 82.855047 \nL 82.504118 81.787543 \nL 82.897655 81.519689 \nL 83.291191 81.67621 \nL 83.689773 81.467887 \nL 84.083309 84.391809 \nL 85.263918 82.786477 \nL 85.6625 82.427236 \nL 86.056036 85.085193 \nL 86.449573 83.91373 \nL 86.843109 83.427908 \nL 87.635227 83.123359 \nL 88.028764 85.383713 \nL 88.4223 84.693901 \nL 89.209373 84.175423 \nL 89.607955 83.692973 \nL 90.001491 85.858398 \nL 91.1821 84.587737 \nL 91.580682 84.314218 \nL 91.974218 87.562213 \nL 92.367755 86.121423 \nL 92.761291 85.542799 \nL 93.154827 85.52045 \nL 93.553409 85.183425 \nL 93.946945 87.531598 \nL 95.526136 86.051016 \nL 95.919673 88.190213 \nL 97.100282 86.884442 \nL 97.498864 86.656552 \nL 97.8924 89.147529 \nL 98.285936 88.83887 \nL 99.073009 87.594654 \nL 99.471591 87.333928 \nL 99.865127 90.105086 \nL 100.6522 88.887696 \nL 101.045736 88.304516 \nL 101.444318 88.046501 \nL 101.837855 90.081341 \nL 102.624927 89.102644 \nL 103.417045 88.578173 \nL 103.810582 91.149055 \nL 104.204118 90.464301 \nL 105.384727 89.247908 \nL 105.389773 89.255615 \nL 105.783309 92.073334 \nL 106.963918 90.272968 \nL 107.3625 90.115156 \nL 107.756036 92.735176 \nL 108.149573 91.687432 \nL 109.335227 90.55529 \nL 109.728764 93.02061 \nL 111.307955 91.255705 \nL 111.701491 93.316333 \nL 113.280682 91.797193 \nL 113.674218 94.782441 \nL 114.067755 93.874125 \nL 115.253409 92.479116 \nL 115.646945 95.182813 \nL 116.040482 94.170655 \nL 116.434018 93.61502 \nL 116.827555 93.415139 \nL 117.226136 92.938182 \nL 117.619673 98.284628 \nL 118.013209 99.172125 \nL 118.800282 100.056385 \nL 119.198864 100.420748 \nL 119.5924 102.657413 \nL 120.379473 102.673235 \nL 120.773009 102.604017 \nL 121.171591 102.649661 \nL 121.565127 103.266802 \nL 122.3522 103.628471 \nL 123.144318 103.583728 \nL 123.537855 104.236112 \nL 123.931391 104.471372 \nL 124.718464 104.500794 \nL 125.117045 104.374535 \nL 125.510582 105.859811 \nL 125.904118 105.558554 \nL 126.297655 105.488453 \nL 126.691191 105.148529 \nL 127.089773 104.982422 \nL 127.483309 106.002914 \nL 128.270382 105.687399 \nL 129.0625 105.694912 \nL 129.456036 106.458826 \nL 130.243109 106.281858 \nL 131.035227 105.992721 \nL 131.428764 107.25829 \nL 132.215836 106.26678 \nL 133.007955 106.223259 \nL 133.401491 107.557051 \nL 133.795027 107.006212 \nL 134.980682 106.828074 \nL 135.374218 107.729948 \nL 135.767755 107.748948 \nL 136.161291 107.470817 \nL 136.554827 107.402052 \nL 136.953409 107.195691 \nL 137.346945 107.857489 \nL 137.740482 107.578156 \nL 138.134018 107.710438 \nL 138.926136 107.526526 \nL 139.319673 108.255431 \nL 140.898864 107.76153 \nL 141.2924 108.704188 \nL 141.685936 108.321883 \nL 142.871591 108.236118 \nL 143.265127 108.968072 \nL 143.658664 108.751772 \nL 144.0522 108.807079 \nL 144.844318 108.682075 \nL 145.237855 109.274528 \nL 146.418464 108.830784 \nL 146.817045 108.797865 \nL 147.210582 110.058169 \nL 147.604118 109.538187 \nL 148.789773 109.122509 \nL 149.183309 109.768895 \nL 150.363918 109.60329 \nL 150.7625 109.561476 \nL 151.156036 110.191764 \nL 151.943109 110.318572 \nL 152.336646 109.976168 \nL 152.735227 109.937102 \nL 153.128764 109.770478 \nL 153.5223 110.016521 \nL 154.707955 109.822218 \nL 155.101491 110.544168 \nL 155.888564 110.466985 \nL 156.680682 110.292843 \nL 157.074218 110.942078 \nL 157.467755 110.790848 \nL 158.254827 110.710851 \nL 158.653409 110.649312 \nL 159.046945 111.185913 \nL 159.440482 111.276681 \nL 159.834018 111.174064 \nL 160.227555 110.941544 \nL 160.626136 110.916636 \nL 161.019673 111.869763 \nL 162.598864 111.318924 \nL 162.9924 112.180917 \nL 163.385936 111.635099 \nL 163.779473 111.5946 \nL 164.173009 111.33464 \nL 164.571591 111.242039 \nL 165.358664 111.801396 \nL 165.7522 111.913409 \nL 166.145736 111.83151 \nL 166.544318 111.622324 \nL 166.937855 112.548126 \nL 167.331391 112.138787 \nL 167.724927 112.239796 \nL 168.517045 111.915222 \nL 168.910582 112.831825 \nL 169.304118 112.246168 \nL 170.489773 111.980262 \nL 170.883309 112.948332 \nL 171.276846 112.865314 \nL 171.670382 112.566671 \nL 172.063918 112.601356 \nL 172.4625 112.345315 \nL 172.856036 113.329744 \nL 173.249573 112.574368 \nL 173.643109 112.802811 \nL 174.435227 112.595762 \nL 174.828764 113.510877 \nL 175.2223 113.595316 \nL 175.615836 113.536508 \nL 176.009373 113.176143 \nL 176.407955 113.095952 \nL 176.801491 113.422211 \nL 177.588564 113.202342 \nL 177.9821 113.084086 \nL 178.380682 112.830901 \nL 178.774218 113.865244 \nL 179.954827 113.198638 \nL 180.353409 113.084799 \nL 180.746945 113.951705 \nL 181.534018 113.870974 \nL 182.326136 113.426618 \nL 182.719673 114.357905 \nL 183.113209 114.154852 \nL 183.506746 113.747765 \nL 184.298864 113.70831 \nL 184.6924 114.811798 \nL 185.479473 114.136691 \nL 186.271591 113.878967 \nL 186.665127 114.723921 \nL 187.058664 114.58731 \nL 187.845736 114.09945 \nL 188.244318 113.906208 \nL 188.637855 114.856069 \nL 189.424927 114.866458 \nL 190.217045 114.333001 \nL 190.610582 115.558949 \nL 191.397655 114.902384 \nL 191.791191 114.619815 \nL 192.189773 114.568805 \nL 192.583309 115.365856 \nL 194.1625 114.672075 \nL 194.556036 115.560916 \nL 194.949573 115.522553 \nL 195.343109 115.233274 \nL 195.736646 115.098719 \nL 196.135227 114.844255 \nL 196.528764 115.84575 \nL 197.315836 115.67717 \nL 198.107955 115.405764 \nL 198.501491 116.002148 \nL 199.6821 115.258314 \nL 200.080682 115.283094 \nL 200.474218 116.314271 \nL 201.261291 115.794541 \nL 201.654827 115.600192 \nL 202.053409 115.61729 \nL 202.446945 116.335081 \nL 202.840482 116.213513 \nL 203.234018 116.210139 \nL 204.026136 115.764316 \nL 204.813209 116.098687 \nL 205.206746 116.132793 \nL 205.998864 115.938325 \nL 206.3924 116.870572 \nL 207.179473 116.48024 \nL 207.971591 116.113862 \nL 208.365127 117.101211 \nL 208.758664 116.589444 \nL 209.1522 116.577804 \nL 209.944318 116.238744 \nL 210.337855 117.369262 \nL 210.731391 116.913192 \nL 211.917045 116.493947 \nL 212.310582 117.073377 \nL 212.704118 116.82687 \nL 213.097655 116.832439 \nL 213.889773 116.580697 \nL 214.283309 118.203081 \nL 215.463918 117.116745 \nL 215.8625 116.990128 \nL 215.8625 116.990128 \n\" clip-path=\"url(#p397b4bb489)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <path d=\"M 18.983309 136.922727 \nL 19.770382 136.523395 \nL 20.5625 136.312784 \nL 20.956036 135.772227 \nL 22.535227 135.488174 \nL 22.928764 135.115176 \nL 23.3223 134.91595 \nL 24.507955 134.78844 \nL 24.901491 134.19161 \nL 25.295027 134.142793 \nL 26.0821 134.183693 \nL 26.480682 134.102406 \nL 26.874218 133.611082 \nL 28.054827 133.692224 \nL 28.453409 133.657696 \nL 28.846945 133.170409 \nL 30.426136 133.085474 \nL 30.819673 132.774595 \nL 31.606746 132.613631 \nL 32.398864 132.599138 \nL 32.7924 132.196706 \nL 33.973009 132.180214 \nL 34.765127 131.961857 \nL 35.5522 131.815845 \nL 36.344318 131.796131 \nL 36.737855 131.33647 \nL 37.524927 131.451696 \nL 38.317045 131.453114 \nL 38.710582 131.003986 \nL 39.104118 131.122731 \nL 40.683309 131.075233 \nL 41.076846 130.886562 \nL 41.863918 130.926143 \nL 42.2625 130.908291 \nL 42.656036 130.542203 \nL 43.049573 130.448527 \nL 43.836646 130.584423 \nL 44.235227 130.585297 \nL 45.0223 130.193887 \nL 46.207955 130.184847 \nL 46.601491 129.689884 \nL 47.7821 129.957718 \nL 48.180682 129.941415 \nL 48.967755 129.593569 \nL 50.153409 129.6611 \nL 50.546945 129.243933 \nL 51.334018 129.341567 \nL 52.126136 129.439272 \nL 52.519673 128.987973 \nL 52.913209 129.172686 \nL 54.098864 129.202164 \nL 54.4924 128.592159 \nL 55.279473 128.881543 \nL 56.071591 129.003519 \nL 56.465127 128.370503 \nL 57.2522 128.665165 \nL 58.044318 128.751131 \nL 58.437855 128.352032 \nL 58.831391 128.536745 \nL 60.017045 128.548798 \nL 60.410582 128.030103 \nL 60.804118 128.268911 \nL 61.989773 128.379661 \nL 62.383309 127.977328 \nL 63.563918 128.173915 \nL 63.9625 128.176801 \nL 64.356036 127.840112 \nL 65.536646 128.010312 \nL 65.935227 127.980791 \nL 66.328764 127.647483 \nL 67.907955 127.796374 \nL 68.301491 127.481241 \nL 69.880682 127.545039 \nL 70.274218 126.998347 \nL 70.667755 127.041887 \nL 71.061291 127.274538 \nL 71.853409 127.380643 \nL 72.246945 126.995709 \nL 72.640482 127.16327 \nL 73.826136 127.241013 \nL 74.219673 126.871687 \nL 75.006746 126.986033 \nL 75.798864 127.020238 \nL 76.1924 126.48115 \nL 77.771591 126.867962 \nL 78.165127 126.367683 \nL 78.558664 126.535245 \nL 79.744318 126.664576 \nL 80.137855 125.956037 \nL 80.531391 126.258175 \nL 81.318464 126.514135 \nL 81.717045 126.527053 \nL 82.110582 126.040477 \nL 82.504118 126.316228 \nL 83.689773 126.37583 \nL 84.083309 125.73702 \nL 85.6625 126.141356 \nL 86.056036 125.54439 \nL 86.843109 125.972749 \nL 87.635227 126.01806 \nL 88.028764 125.470505 \nL 88.4223 125.643344 \nL 89.209373 125.735041 \nL 89.607955 125.885806 \nL 90.001491 125.285791 \nL 91.1821 125.681606 \nL 91.580682 125.723518 \nL 91.974218 124.860951 \nL 92.367755 125.26864 \nL 92.761291 125.411572 \nL 93.553409 125.516444 \nL 93.946945 125.085246 \nL 95.526136 125.405793 \nL 95.919673 124.831925 \nL 97.498864 125.214526 \nL 97.8924 124.575965 \nL 98.285936 124.631379 \nL 99.073009 125.024554 \nL 99.471591 125.078056 \nL 99.865127 124.520551 \nL 101.045736 124.915046 \nL 101.444318 124.974256 \nL 101.837855 124.30945 \nL 103.018464 124.686793 \nL 103.417045 124.788784 \nL 103.810582 124.050851 \nL 104.597655 124.439629 \nL 105.389773 124.635981 \nL 105.783309 124.024464 \nL 107.3625 124.48107 \nL 107.756036 123.75531 \nL 108.543109 124.091312 \nL 109.335227 124.289802 \nL 109.728764 123.789614 \nL 111.307955 124.185475 \nL 111.701491 123.586429 \nL 112.488564 123.881971 \nL 113.280682 124.056909 \nL 113.674218 123.22228 \nL 114.067755 123.507267 \nL 115.253409 123.928344 \nL 115.646945 123.298804 \nL 116.434018 123.652398 \nL 117.226136 123.84035 \nL 117.619673 122.364683 \nL 118.406746 121.92401 \nL 119.198864 121.711643 \nL 119.5924 121.098078 \nL 120.379473 121.149973 \nL 121.171591 121.193165 \nL 121.565127 120.839479 \nL 121.958664 120.886977 \nL 122.745736 120.796599 \nL 123.144318 120.831707 \nL 123.537855 120.662682 \nL 125.117045 120.668365 \nL 125.510582 120.287978 \nL 127.089773 120.551919 \nL 127.483309 120.171873 \nL 128.663918 120.337455 \nL 129.0625 120.332725 \nL 129.456036 119.934384 \nL 131.035227 120.244731 \nL 131.428764 119.886887 \nL 132.215836 120.176271 \nL 133.007955 120.209428 \nL 133.401491 119.892164 \nL 133.795027 120.037296 \nL 134.980682 120.007623 \nL 135.374218 119.747032 \nL 136.953409 119.845335 \nL 137.346945 119.747032 \nL 137.740482 119.9014 \nL 138.527555 119.835431 \nL 138.926136 119.871154 \nL 139.319673 119.480517 \nL 140.898864 119.771568 \nL 141.2924 119.448852 \nL 141.685936 119.562319 \nL 142.473009 119.599921 \nL 143.658664 119.549125 \nL 144.445736 119.553083 \nL 144.844318 119.563439 \nL 145.237855 119.361773 \nL 146.024927 119.447973 \nL 146.817045 119.477554 \nL 147.210582 119.129562 \nL 147.604118 119.307679 \nL 148.789773 119.415905 \nL 149.183309 119.211364 \nL 149.576846 119.30504 \nL 150.363918 119.306359 \nL 150.7625 119.312104 \nL 151.156036 119.121646 \nL 152.336646 119.190913 \nL 154.707955 119.239918 \nL 155.101491 118.905267 \nL 156.2821 119.061614 \nL 156.680682 119.081319 \nL 157.074218 118.823466 \nL 157.861291 118.936933 \nL 158.653409 118.975937 \nL 159.046945 119.074148 \nL 159.440482 118.96464 \nL 160.626136 119.012821 \nL 161.019673 118.64403 \nL 162.200282 118.717915 \nL 162.598864 118.805746 \nL 162.9924 118.567506 \nL 163.385936 118.740345 \nL 164.965127 118.778607 \nL 165.7522 118.681852 \nL 166.544318 118.745679 \nL 166.937855 118.514731 \nL 167.331391 118.617643 \nL 168.118464 118.613025 \nL 168.517045 118.650835 \nL 168.910582 118.337934 \nL 169.697655 118.530563 \nL 170.489773 118.639243 \nL 170.883309 118.40918 \nL 172.4625 118.564422 \nL 172.856036 118.111 \nL 173.249573 118.403903 \nL 174.036646 118.374877 \nL 174.435227 118.405296 \nL 175.2223 118.169053 \nL 178.380682 118.369993 \nL 178.774218 117.923648 \nL 179.561291 118.215671 \nL 180.353409 118.330475 \nL 180.746945 118.076697 \nL 181.534018 118.04855 \nL 182.326136 118.231417 \nL 182.719673 117.947397 \nL 183.506746 118.191922 \nL 184.298864 118.178199 \nL 184.6924 117.818098 \nL 185.873009 118.060204 \nL 186.271591 118.087044 \nL 186.665127 117.847124 \nL 187.4522 118.007209 \nL 188.244318 118.119712 \nL 188.637855 117.807543 \nL 190.217045 118.000631 \nL 190.610582 117.554222 \nL 191.397655 117.730139 \nL 192.189773 117.853624 \nL 192.583309 117.680882 \nL 193.763918 117.876151 \nL 194.1625 117.899992 \nL 194.556036 117.62283 \nL 194.949573 117.552903 \nL 196.135227 117.776168 \nL 196.528764 117.4302 \nL 198.107955 117.658668 \nL 198.501491 117.498808 \nL 200.080682 117.660249 \nL 200.474218 117.40909 \nL 201.654827 117.673626 \nL 202.053409 117.669733 \nL 202.446945 117.337843 \nL 203.627555 117.539049 \nL 204.026136 117.585955 \nL 204.419673 117.435478 \nL 205.206746 117.458347 \nL 205.998864 117.523253 \nL 206.3924 117.237571 \nL 207.971591 117.470562 \nL 208.365127 117.126743 \nL 208.758664 117.336524 \nL 209.545736 117.370168 \nL 209.944318 117.434205 \nL 210.337855 117.250764 \nL 211.124927 117.391498 \nL 211.917045 117.407333 \nL 212.310582 117.034386 \nL 212.704118 117.166324 \nL 213.889773 117.297736 \nL 214.283309 116.723012 \nL 215.463918 117.152471 \nL 215.8625 117.179709 \nL 215.8625 117.179709 \n\" clip-path=\"url(#p397b4bb489)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_23\">\n    <path d=\"M 20.5625 135.816964 \nL 22.535227 135.337478 \nL 24.507955 134.275759 \nL 26.480682 133.611855 \nL 28.453409 133.485397 \nL 30.426136 132.681863 \nL 32.398864 132.589654 \nL 34.371591 132.107533 \nL 36.344318 131.941557 \nL 38.317045 131.354055 \nL 40.289773 130.953605 \nL 42.2625 131.127485 \nL 44.235227 130.682248 \nL 46.207955 130.395083 \nL 48.180682 130.192223 \nL 50.153409 130.402986 \nL 52.126136 129.957749 \nL 54.098864 129.849733 \nL 56.071591 129.860271 \nL 58.044318 129.778601 \nL 60.017045 129.720641 \nL 61.989773 129.346536 \nL 63.9625 129.330729 \nL 65.935227 129.193733 \nL 67.907955 129.235886 \nL 69.880682 128.996143 \nL 71.853409 129.135773 \nL 73.826136 128.946086 \nL 75.798864 128.830167 \nL 77.771591 128.92501 \nL 79.744318 128.477139 \nL 81.717045 129.09889 \nL 83.689773 128.506118 \nL 85.6625 128.635211 \nL 87.635227 128.569347 \nL 89.607955 128.682633 \nL 91.580682 128.35595 \nL 93.553409 128.406006 \nL 95.526136 128.253203 \nL 97.498864 128.648384 \nL 99.471591 128.145187 \nL 101.444318 128.174167 \nL 103.417045 128.506118 \nL 105.389773 128.213685 \nL 107.3625 128.110938 \nL 109.335227 128.008191 \nL 111.307955 128.074054 \nL 113.280682 127.881733 \nL 115.253409 128.195243 \nL 117.226136 128.324335 \nL 119.198864 127.478648 \nL 121.171591 127.373267 \nL 123.144318 127.38117 \nL 125.117045 127.365363 \nL 127.089773 127.265251 \nL 129.0625 127.246809 \nL 131.035227 127.357459 \nL 133.007955 127.591933 \nL 134.980682 127.349556 \nL 136.953409 127.302134 \nL 138.926136 127.35219 \nL 140.898864 127.296865 \nL 142.871591 127.462841 \nL 144.844318 127.291596 \nL 146.817045 127.325845 \nL 148.789773 127.32848 \nL 150.7625 127.275789 \nL 152.735227 127.365363 \nL 154.707955 127.307403 \nL 156.680682 127.354825 \nL 158.653409 127.399612 \nL 160.626136 127.515532 \nL 162.598864 127.457572 \nL 164.571591 127.46811 \nL 166.544318 127.486552 \nL 168.517045 127.528705 \nL 170.489773 127.541877 \nL 172.4625 127.476014 \nL 174.435227 127.576126 \nL 176.407955 127.565588 \nL 178.380682 127.396978 \nL 180.353409 127.536608 \nL 182.326136 127.454937 \nL 184.298864 127.570857 \nL 186.271591 127.494456 \nL 188.244318 127.539243 \nL 190.217045 127.626182 \nL 192.189773 127.581395 \nL 194.1625 127.544512 \nL 196.135227 127.489186 \nL 198.107955 127.544512 \nL 200.080682 127.486552 \nL 202.053409 127.586664 \nL 204.026136 127.504994 \nL 205.998864 127.747371 \nL 207.971591 127.547146 \nL 209.944318 127.539243 \nL 211.917045 127.744737 \nL 213.889773 127.718391 \nL 215.8625 127.681508 \n\" clip-path=\"url(#p397b4bb489)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 20.5625 143.1 \nL 20.5625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 215.8625 143.1 \nL 215.8625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 20.5625 143.1 \nL 215.8625 143.1 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 20.5625 7.2 \nL 215.8625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 131.09375 59.234375 \nL 208.8625 59.234375 \nQ 210.8625 59.234375 210.8625 57.234375 \nL 210.8625 14.2 \nQ 210.8625 12.2 208.8625 12.2 \nL 131.09375 12.2 \nQ 129.09375 12.2 129.09375 14.2 \nL 129.09375 57.234375 \nQ 129.09375 59.234375 131.09375 59.234375 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_24\">\n     <path d=\"M 133.09375 20.298438 \nL 143.09375 20.298438 \nL 153.09375 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- train loss -->\n     <g transform=\"translate(161.09375 23.798438)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"264.550781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"292.333984\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"353.515625\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"405.615234\"/>\n     </g>\n    </g>\n    <g id=\"line2d_25\">\n     <path d=\"M 133.09375 34.976562 \nL 143.09375 34.976562 \nL 153.09375 34.976562 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- train acc -->\n     <g transform=\"translate(161.09375 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"264.550781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"325.830078\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"380.810547\"/>\n     </g>\n    </g>\n    <g id=\"line2d_26\">\n     <path d=\"M 133.09375 49.654688 \nL 143.09375 49.654688 \nL 153.09375 49.654688 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- valid acc -->\n     <g transform=\"translate(161.09375 53.154688)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"176.025391\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.501953\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"271.289062\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"332.568359\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"387.548828\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p397b4bb489\">\n   <rect x=\"20.5625\" y=\"7.2\" width=\"195.3\" height=\"135.9\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = mobilenext(num_classes=100)\n",
    "devices = d2l.try_gpu()\n",
    "num_epochs = 100\n",
    "lr = 2e-4\n",
    "wd = 5e-4\n",
    "lr_period = 50\n",
    "lr_decay = 0.1\n",
    "trainloader, validloader = load_data_cifar100()\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
    "train(net, trainloader, validloader, num_epochs, loss, trainer, lr_period, lr_decay)\n",
    "torch.save(net.state_dict(), \"mobilenext.pth\", _use_new_zipfile_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
